import PyPDF2
import re
from typing import List, Dict, Any
from app.models import ChromaQuestion


class UrduTransliterationParser:
    """Parser for Urdu questions written in English transliteration"""
    
    def __init__(self):
        # Common Urdu transliteration patterns
        self.question_patterns = [
            r'^\d+\.\s*"([^"]+)"',  # Numbered questions in quotes
            r'^\d+\.\s*([^?]+)\?',  # Numbered questions ending with ?
            r'^[Aa]p\s+[^?]*\?',  # Questions starting with "Ap"
            r'^[Kk]ya\s+[^?]*\?',  # Questions starting with "Kya"
            r'^[Aa]ap\s+[^?]*\?',  # Questions starting with "Aap"
            r'^Please\s+[^?]*\?',  # Questions starting with "Please"
            r'^[Aa]pna\s+[^?]*\?',  # Questions starting with "Apna"
            r'^[Aa]pne\s+[^?]*\?',  # Questions starting with "Apne"
            r'^[Kk]ya\s+[Aa]ap\s+[^?]*\?',  # Questions starting with "Kya aap"
            r'^[Aa]ap\s+[Kk]ya\s+[^?]*\?',  # Questions starting with "Aap kya"
        ]
        
        # Transliteration mapping for common Urdu words
        self.transliteration_map = {
            # Basic words
            'aap': 'Ø¢Ù¾',
            'ap': 'Ø¢Ù¾',
            'kya': 'Ú©ÛŒØ§',
            'hai': 'ÛÛ’',
            'hain': 'ÛÛŒÚº',
            'ka': 'Ú©Ø§',
            'ki': 'Ú©ÛŒ',
            'ke': 'Ú©Û’',
            'ko': 'Ú©Ùˆ',
            'mein': 'Ù…ÛŒÚº',
            'se': 'Ø³Û’',
            'tak': 'ØªÚ©',
            'ya': 'ÛŒØ§',
            'aur': 'Ø§ÙˆØ±',
            'bhi': 'Ø¨Ú¾ÛŒ',
            'nahi': 'Ù†ÛÛŒÚº',
            'nahin': 'Ù†ÛÛŒÚº',
            'tou': 'ØªÙˆ',
            'agar': 'Ø§Ú¯Ø±',
            'to': 'ØªÙˆ',
            'abhi': 'Ø§Ø¨Ú¾ÛŒ',
            'kitna': 'Ú©ØªÙ†Ø§',
            'kitni': 'Ú©ØªÙ†ÛŒ',
            'kya': 'Ú©ÛŒØ§',
            'konsi': 'Ú©ÙˆÙ†Ø³ÛŒ',
            'konsa': 'Ú©ÙˆÙ†Ø³Ø§',
            'kahan': 'Ú©ÛØ§Úº',
            'kab': 'Ú©Ø¨',
            'kyun': 'Ú©ÛŒÙˆÚº',
            'kaise': 'Ú©ÛŒØ³Û’',
            
            # Medical terms
            'dard': 'Ø¯Ø±Ø¯',
            'takleef': 'ØªÚ©Ù„ÛŒÙ',
            'bimari': 'Ø¨ÛŒÙ…Ø§Ø±ÛŒ',
            'alamat': 'Ø¹Ù„Ø§Ù…Ø§Øª',
            'symptom': 'Ø¹Ù„Ø§Ù…Øª',
            'test': 'Ù¹ÛŒØ³Ù¹',
            'blood': 'Ø¨Ù„Úˆ',
            'pressure': 'Ù¾Ø±ÛŒØ´Ø±',
            'sugar': 'Ø´ÙˆÚ¯Ø±',
            'diabetes': 'Ø°ÛŒØ§Ø¨ÛŒØ·Ø³',
            'heart': 'Ø¯Ù„',
            'chest': 'Ø³ÛŒÙ†Û',
            'head': 'Ø³Ø±',
            'stomach': 'Ù¾ÛŒÙ¹',
            'back': 'Ú©Ù…Ø±',
            'joint': 'Ø¬ÙˆÚ‘',
            'fever': 'Ø¨Ø®Ø§Ø±',
            'cough': 'Ú©Ú¾Ø§Ù†Ø³ÛŒ',
            'breath': 'Ø³Ø§Ù†Ø³',
            'pain': 'Ø¯Ø±Ø¯',
            'ache': 'ØªÚ©Ù„ÛŒÙ',
            'fatigue': 'ØªÚ¾Ú©Ø§ÙˆÙ¹',
            'weakness': 'Ú©Ù…Ø²ÙˆØ±ÛŒ',
            'sleep': 'Ù†ÛŒÙ†Ø¯',
            'hunger': 'Ø¨Ú¾ÙˆÚ©',
            'thirst': 'Ù¾ÛŒØ§Ø³',
            'urine': 'Ù¾ÛŒØ´Ø§Ø¨',
            'stool': 'Ù¾Ø§Ø®Ø§Ù†Û',
            'vomit': 'Ø§Ù„Ù¹ÛŒ',
            'nausea': 'Ù…ØªÙ„ÛŒ',
            'dizziness': 'Ú†Ú©Ø±',
            'fainting': 'Ø¨Û’ ÛÙˆØ´ÛŒ',
            'bleeding': 'Ø®ÙˆÙ† Ø¨ÛÙ†Ø§',
            'swelling': 'Ø³ÙˆØ¬Ù†',
            'rash': 'Ø®Ø§Ø±Ø´',
            'itch': 'Ú©Ú¾Ø¬Ù„ÛŒ',
            'burning': 'Ø¬Ù„Ù†',
            'numbness': 'Ø³Ù†',
            'tingling': 'Ø¬Ú¾Ù†Ø¬Ú¾Ù†Ø§ÛÙ¹',
            
            # Body parts
            'sar': 'Ø³Ø±',
            'aankh': 'Ø¢Ù†Ú©Ú¾',
            'kaan': 'Ú©Ø§Ù†',
            'naak': 'Ù†Ø§Ú©',
            'muh': 'Ù…Ù†Û',
            'dant': 'Ø¯Ø§Ù†Øª',
            'gala': 'Ú¯Ù„Ø§',
            'gardan': 'Ú¯Ø±Ø¯Ù†',
            'kandha': 'Ú©Ù†Ø¯Ú¾Ø§',
            'bazu': 'Ø¨Ø§Ø²Ùˆ',
            'hath': 'ÛØ§ØªÚ¾',
            'ungli': 'Ø§Ù†Ú¯Ù„ÛŒ',
            'chhati': 'Ú†Ú¾Ø§ØªÛŒ',
            'pet': 'Ù¾ÛŒÙ¹',
            'kamar': 'Ú©Ù…Ø±',
            'jangh': 'Ø±Ø§Ù†',
            'ghutna': 'Ú¯Ú¾Ù¹Ù†Ø§',
            'paon': 'Ù¾Ø§Ø¤Úº',
            'pair': 'Ù¾ÛŒØ±',
            
            # Family terms
            'shohar': 'Ø´ÙˆÛØ±',
            'biwi': 'Ø¨ÛŒÙˆÛŒ',
            'bacha': 'Ø¨Ú†Û',
            'bachay': 'Ø¨Ú†Û’',
            'beta': 'Ø¨ÛŒÙ¹Ø§',
            'beti': 'Ø¨ÛŒÙ¹ÛŒ',
            'maa': 'Ù…Ø§Úº',
            'baap': 'Ø¨Ø§Ù¾',
            'dada': 'Ø¯Ø§Ø¯Ø§',
            'dadi': 'Ø¯Ø§Ø¯ÛŒ',
            'nana': 'Ù†Ø§Ù†Ø§',
            'nani': 'Ù†Ø§Ù†ÛŒ',
            'bhai': 'Ø¨Ú¾Ø§Ø¦ÛŒ',
            'behen': 'Ø¨ÛÙ†',
            'chacha': 'Ú†Ú†Ø§',
            'chachi': 'Ú†Ú†ÛŒ',
            'mama': 'Ù…Ø§Ù…Ø§',
            'mami': 'Ù…Ø§Ù…ÛŒ',
            'phupho': 'Ù¾Ú¾ÙˆÙ¾Ú¾Ùˆ',
            'phupha': 'Ù¾Ú¾ÙˆÙ¾Ú¾Ø§',
            'khala': 'Ø®Ø§Ù„Û',
            'khalu': 'Ø®Ø§Ù„Ùˆ',
            'bua': 'Ø¨ÙˆØ§',
            'fufa': 'ÙÙˆÙØ§',
            
            # Time and numbers
            'din': 'Ø¯Ù†',
            'raat': 'Ø±Ø§Øª',
            'subah': 'ØµØ¨Ø­',
            'dopahar': 'Ø¯ÙˆÙ¾ÛØ±',
            'shaam': 'Ø´Ø§Ù…',
            'hafte': 'ÛÙØªÛ’',
            'mahine': 'Ù…ÛÛŒÙ†Û’',
            'saal': 'Ø³Ø§Ù„',
            'pehle': 'Ù¾ÛÙ„Û’',
            'baad': 'Ø¨Ø¹Ø¯',
            'abhi': 'Ø§Ø¨Ú¾ÛŒ',
            'kal': 'Ú©Ù„',
            'parson': 'Ù¾Ø±Ø³ÙˆÚº',
            'aaj': 'Ø¢Ø¬',
            
            # Common phrases
            'theek hai': 'Ù¹Ú¾ÛŒÚ© ÛÛ’',
            'accha': 'Ø§Ú†Ú¾Ø§',
            'buri': 'Ø¨Ø±ÛŒ',
            'zada': 'Ø²ÛŒØ§Ø¯Û',
            'kam': 'Ú©Ù…',
            'bohot': 'Ø¨ÛØª',
            'thoda': 'ØªÚ¾ÙˆÚ‘Ø§',
            'bilkul': 'Ø¨Ø§Ù„Ú©Ù„',
            'zaroor': 'Ø¶Ø±ÙˆØ±',
            'shayad': 'Ø´Ø§ÛŒØ¯',
            'mumkin': 'Ù…Ù…Ú©Ù†',
            'imkaan': 'Ø§Ù…Ú©Ø§Ù†',
        }
        
        # Alert keywords in transliteration
        self.alert_keywords = {
            'red': [
                'chest pain', 'sine mein dard', 'breathlessness', 'saans lene mein mushkil',
                'fainting', 'be hoshi', 'severe bleeding', 'shadeed khoon bahna',
                'heart attack', 'dil ka dora', 'stroke', 'falaj', 'emergency', 'emergency'
            ],
            'yellow': [
                'mild', 'halka', 'headache', 'sar dard', 'cough', 'khansi',
                'fatigue', 'thakawat', 'fever', 'bukhar', 'discomfort', 'takleef'
            ]
        }
        
        # Question type keywords
        self.question_type_keywords = {
            'onboarding': [
                'naam', 'name', 'shanaakhti', 'identity', 'card', 'number',
                'jamat', 'education', 'ilaqa', 'area', 'kaam', 'work',
                'umar', 'age', 'shaadi', 'marriage', 'bachay', 'children'
            ],
            'demographic': [
                'gender', 'jins', 'male', 'mard', 'female', 'aurat', 'khawateen',
                'children', 'bachay', 'occupation', 'pesha', 'education', 'taleem',
                'income', 'aamadni', 'marital', 'shaadi', 'family', 'khandan'
            ],
            'symptom': [
                'pain', 'dard', 'ache', 'takleef', 'fever', 'bukhar', 'cough', 'khansi',
                'symptom', 'alamat', 'problem', 'masla', 'condition', 'halat',
                'bimari', 'disease', 'illness', 'sick', 'patient'
            ]
        }

    def parse_pdf(self, pdf_path: str) -> List[ChromaQuestion]:
        """Parse PDF and extract questions with transliteration handling"""
        questions = []
        
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                
                for page_num, page in enumerate(pdf_reader.pages):
                    text = page.extract_text()
                    page_questions = self._extract_questions_from_text(text, page_num)
                    questions.extend(page_questions)
                    
        except Exception as e:
            print(f"Error reading PDF: {e}")
            
        return questions

    def _extract_questions_from_text(self, text: str, page_num: int) -> List[ChromaQuestion]:
        """Extract questions from text by reconstructing broken lines"""
        questions = []
        lines = text.split('\n')
        
        # Reconstruct text by joining words that are on separate lines
        reconstructed_text = ""
        current_question = ""
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
                
            # Check if this line starts a new question
            if (line.startswith('Please') or 
                line.startswith('Ap') or 
                line.startswith('Aap') or 
                line.startswith('Kya') or
                line.startswith('â—')):
                
                # Save previous question if it exists
                if current_question.strip():
                    question_text = current_question.strip()
                    if '?' in question_text or len(question_text) > 10:
                        question_data = self._create_question_data(question_text, page_num, i)
                        questions.append(question_data)
                
                # Start new question
                if line.startswith('â—'):
                    current_question = ""
                else:
                    current_question = line + " "
            else:
                # Continue current question
                current_question += line + " "
        
        # Don't forget the last question
        if current_question.strip():
            question_text = current_question.strip()
            if '?' in question_text or len(question_text) > 10:
                question_data = self._create_question_data(question_text, page_num, len(lines))
                questions.append(question_data)
        
        return questions

    def _convert_to_urdu(self, text: str) -> str:
        """Convert English transliteration to Urdu text"""
        # Convert to lowercase for matching
        text_lower = text.lower()
        
        # Apply transliteration mapping
        for eng, urdu in self.transliteration_map.items():
            # Use word boundaries to avoid partial matches
            pattern = r'\b' + re.escape(eng) + r'\b'
            text_lower = re.sub(pattern, urdu, text_lower, flags=re.IGNORECASE)
        
        return text_lower

    def _create_question_data(self, text: str, page_num: int, line_num: int) -> ChromaQuestion:
        """Create ChromaQuestion object with enhanced metadata extraction"""
        question_id = f"q_{page_num}_{line_num}_{hash(text) % 10000}"
        
        # Determine question type
        question_type = self._determine_question_type(text)
        
        # Determine alert level
        alert_flag = self._determine_alert_level(text)
        
        # Extract condition (for conditional questions)
        condition = self._extract_condition(text)
        
        # Extract symptom type
        symptom = self._extract_symptom_type(text)
        
        return ChromaQuestion(
            id=question_id,
            question_text=text,
            type=question_type,
            condition=condition,
            symptom=symptom,
            alert_flag=alert_flag
        )

    def _determine_question_type(self, text: str) -> str:
        """Determine question type based on content analysis"""
        text_lower = text.lower()
        
        # Check for demographic keywords
        for keyword in self.question_type_keywords['demographic']:
            if keyword.lower() in text_lower:
                return 'demographic'
        
        # Check for symptom keywords
        for keyword in self.question_type_keywords['symptom']:
            if keyword.lower() in text_lower:
                return 'symptom'
        
        # Check for onboarding keywords
        for keyword in self.question_type_keywords['onboarding']:
            if keyword.lower() in text_lower:
                return 'onboarding'
        
        # Default to onboarding if unclear
        return 'onboarding'

    def _determine_alert_level(self, text: str) -> str:
        """Determine alert level based on content analysis"""
        text_lower = text.lower()
        
        # Check for red alert keywords
        for keyword in self.alert_keywords['red']:
            if keyword.lower() in text_lower:
                return 'red'
        
        # Check for yellow alert keywords
        for keyword in self.alert_keywords['yellow']:
            if keyword.lower() in text_lower:
                return 'yellow'
        
        return 'none'

    def _extract_condition(self, text: str) -> str:
        """Extract conditional logic from question text"""
        text_lower = text.lower()
        
        # Look for conditional patterns
        if 'if' in text_lower and 'children' in text_lower:
            if '1' in text or 'one' in text_lower:
                return 'if_children=1'
            elif '2' in text or 'two' in text_lower:
                return 'if_children=2'
            elif '3' in text or 'three' in text_lower:
                return 'if_children=3'
        
        if 'if' in text_lower and 'pregnant' in text_lower:
            return 'if_pregnant=yes'
        
        if 'if' in text_lower and 'diabetes' in text_lower:
            return 'if_diabetes=yes'
        
        return None

    def _extract_symptom_type(self, text: str) -> str:
        """Extract specific symptom type from question text"""
        text_lower = text.lower()
        
        symptom_mapping = {
            'chest': 'chest_pain',
            'sine': 'chest_pain',
            'cough': 'cough',
            'khansi': 'cough',
            'head': 'headache',
            'sar': 'headache',
            'fever': 'fever',
            'bukhar': 'fever',
            'stomach': 'stomach_pain',
            'pet': 'stomach_pain',
            'back': 'back_pain',
            'kamar': 'back_pain',
            'joint': 'joint_pain',
            'jod': 'joint_pain'
        }
        
        for keyword, symptom in symptom_mapping.items():
            if keyword in text_lower:
                return symptom
        
        return None

    def validate_questions(self, questions: List[ChromaQuestion]) -> Dict[str, Any]:
        """Validate and provide statistics about parsed questions"""
        stats = {
            'total_questions': len(questions),
            'by_type': {},
            'by_alert': {},
            'with_conditions': 0,
            'with_symptoms': 0,
            'urdu_questions': 0,
            'transliterated_questions': 0
        }
        
        for question in questions:
            # Count by type
            q_type = question.type
            stats['by_type'][q_type] = stats['by_type'].get(q_type, 0) + 1
            
            # Count by alert level
            alert = question.alert_flag
            stats['by_alert'][alert] = stats['by_alert'].get(alert, 0) + 1
            
            # Count conditions and symptoms
            if question.condition:
                stats['with_conditions'] += 1
            if question.symptom:
                stats['with_symptoms'] += 1
            
            # Count language type
            if any('\u0600' <= char <= '\u06FF' for char in question.question_text):
                stats['urdu_questions'] += 1
            else:
                stats['transliterated_questions'] += 1
        
        return stats


# Enhanced Chroma DB setup with Urdu transliteration support
class UrduChromaDBSetup:
    def __init__(self):
        from app.chroma_setup import ChromaDBSetup
        self.base_setup = ChromaDBSetup()
        self.parser = UrduTransliterationParser()

    def setup_with_urdu_parsing(self, pdf_path: str) -> int:
        """Setup Chroma DB with Urdu transliteration parsing"""
        print("ðŸ”„ Parsing PDF with Urdu transliteration parser...")
        questions = self.parser.parse_pdf(pdf_path)
        
        if not questions:
            print("âŒ No questions found in PDF")
            return 0
        
        # Validate questions
        stats = self.parser.validate_questions(questions)
        print(f"ðŸ“Š Parsed {stats['total_questions']} questions:")
        print(f"   - By type: {stats['by_type']}")
        print(f"   - By alert: {stats['by_alert']}")
        print(f"   - With conditions: {stats['with_conditions']}")
        print(f"   - With symptoms: {stats['with_symptoms']}")
        print(f"   - Urdu: {stats['urdu_questions']}, Transliterated: {stats['transliterated_questions']}")
        
        # Show sample questions
        print("\nðŸ“ Sample questions:")
        for i, q in enumerate(questions[:5]):
            print(f"   {i+1}. {q.question_text}")
        
        # Create embeddings
        print("ðŸ”„ Creating embeddings...")
        embeddings = self.base_setup.create_embeddings(questions)
        
        # Store in Chroma DB
        print("ðŸ”„ Storing in Chroma DB...")
        self.base_setup.store_questions_in_chroma(questions, embeddings)
        
        return len(questions)
    
    def get_questions_by_type(self, question_type: str) -> List[Dict]:
        """Get questions by type from Chroma DB"""
        return self.base_setup.get_questions_by_type(question_type)
